"""
é‡è¤‡å®šæ•°å‰Šé™¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ã—ãŸTZ_NYã€ALPACA_ACCOUNTã‚’å…±é€šå®šæ•°ã«ç½®æ›
"""

import os
import re
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
SRC_DIR = PROJECT_ROOT / "src"

# é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ç½®æ›ãƒ«ãƒ¼ãƒ«ã®å®šç¾©
DUPLICATE_PATTERNS = [
    {
        'pattern': r'TZ_NY = ZoneInfo\(["\']US/Eastern["\']\)',
        'replacement': 'TZ_NY = TIMEZONE.NY  # Migrated from common_constants',
        'import_needed': 'from common_constants import TIMEZONE'
    },
    {
        'pattern': r'TZ_UTC = ZoneInfo\(["\']UTC["\']\)',
        'replacement': 'TZ_UTC = TIMEZONE.UTC  # Migrated from common_constants',
        'import_needed': 'from common_constants import TIMEZONE'
    },
    {
        'pattern': r'ALPACA_ACCOUNT = ["\']live["\']',
        'replacement': 'ALPACA_ACCOUNT = ACCOUNT.get_account_type()  # Migrated from common_constants',
        'import_needed': 'from common_constants import ACCOUNT'
    },
    {
        'pattern': r'ALPACA_ACCOUNT = ["\']paper["\']',
        'replacement': 'ALPACA_ACCOUNT = ACCOUNT.get_account_type(override="paper")  # Migrated from common_constants',
        'import_needed': 'from common_constants import ACCOUNT'
    },
    {
        'pattern': r'ALPACA_ACCOUNT = ["\']paper_short["\']',
        'replacement': 'ALPACA_ACCOUNT = ACCOUNT.get_account_type(override="paper_short")  # Migrated from common_constants',
        'import_needed': 'from common_constants import ACCOUNT'
    },
    {
        'pattern': r'ALPACA_ACCOUNT = ["\']paper2["\']',
        'replacement': 'ALPACA_ACCOUNT = ACCOUNT.get_account_type(override="paper2")  # Migrated from common_constants',
        'import_needed': 'from common_constants import ACCOUNT'
    }
]

# ZoneInfoã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å‰Šé™¤ãƒ‘ã‚¿ãƒ¼ãƒ³
ZONINFO_IMPORT_PATTERNS = [
    r'from zoneinfo import ZoneInfo\n',
    r'import zoneinfo\n',
    r', ZoneInfo',
    r'ZoneInfo, ',
    r'ZoneInfo\n'
]


def find_files_with_duplicates():
    """é‡è¤‡å®šæ•°ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    files_with_duplicates = set()
    
    for pattern_info in DUPLICATE_PATTERNS:
        pattern = pattern_info['pattern']
        
        for py_file in SRC_DIR.glob("*.py"):
            if py_file.name in ['common_constants.py', '__init__.py']:
                continue
                
            try:
                content = py_file.read_text(encoding='utf-8')
                if re.search(pattern, content):
                    files_with_duplicates.add(py_file)
                    print(f"Found duplicate in {py_file.name}: {pattern}")
            except Exception as e:
                print(f"Error reading {py_file}: {e}")
    
    return list(files_with_duplicates)


def add_common_imports(content: str, needed_imports: set) -> str:
    """å¿…è¦ãªå…±é€šã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ """
    lines = content.split('\n')
    import_section_end = 0
    
    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ‚äº†ä½ç½®ã‚’è¦‹ã¤ã‘ã‚‹
    for i, line in enumerate(lines):
        if (line.strip() and 
            not line.startswith('import ') and 
            not line.startswith('from ') and
            not line.startswith('#') and
            not line.strip() == ''):
            import_section_end = i
            break
    
    # æ—¢å­˜ã®common_constantsã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
    has_common_constants_import = any(
        'from common_constants import' in line or 'import common_constants' in line
        for line in lines[:import_section_end]
    )
    
    if not has_common_constants_import and needed_imports:
        # æ–°ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ 
        import_line = f"from common_constants import {', '.join(sorted(needed_imports))}"
        lines.insert(import_section_end, import_line)
    
    return '\n'.join(lines)


def remove_zoninfo_imports(content: str) -> str:
    """ä¸è¦ãªZoneInfoã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å‰Šé™¤"""
    for pattern in ZONINFO_IMPORT_PATTERNS:
        content = re.sub(pattern, '', content)
    
    # ç©ºè¡Œã®é€£ç¶šã‚’æ•´ç†
    content = re.sub(r'\n{3,}', '\n\n', content)
    
    return content


def migrate_file(file_path: Path) -> dict:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡å®šæ•°ã‚’ç§»è¡Œ"""
    try:
        content = file_path.read_text(encoding='utf-8')
        original_content = content
        needed_imports = set()
        changes_made = []
        
        # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾ã—ã¦ç½®æ›ã‚’å®Ÿè¡Œ
        for pattern_info in DUPLICATE_PATTERNS:
            pattern = pattern_info['pattern']
            replacement = pattern_info['replacement']
            import_needed = pattern_info['import_needed'].split()[-1]  # TIMEZONE, ACCOUNTç­‰ã‚’æŠ½å‡º
            
            if re.search(pattern, content):
                content = re.sub(pattern, replacement, content)
                needed_imports.add(import_needed)
                changes_made.append(f"Replaced: {pattern}")
        
        # å¿…è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ 
        if needed_imports:
            content = add_common_imports(content, needed_imports)
        
        # ZoneInfoã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å‰Šé™¤
        content = remove_zoninfo_imports(content)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿æ›¸ãè¾¼ã¿
        if content != original_content:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            backup_path = file_path.with_suffix('.py.backup')
            backup_path.write_text(original_content, encoding='utf-8')
            
            # æ›´æ–°ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›¸ãè¾¼ã¿
            file_path.write_text(content, encoding='utf-8')
            
            return {
                'file': file_path.name,
                'status': 'success',
                'changes': changes_made,
                'backup_created': str(backup_path),
                'imports_added': list(needed_imports)
            }
        else:
            return {
                'file': file_path.name,
                'status': 'no_changes',
                'changes': [],
                'backup_created': None,
                'imports_added': []
            }
            
    except Exception as e:
        return {
            'file': file_path.name,
            'status': 'error',
            'error': str(e),
            'changes': [],
            'backup_created': None,
            'imports_added': []
        }


def generate_migration_report(results: list) -> str:
    """ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    report = ["=== Duplicate Constants Migration Report ===\n"]
    
    success_count = sum(1 for r in results if r['status'] == 'success')
    no_change_count = sum(1 for r in results if r['status'] == 'no_changes')
    error_count = sum(1 for r in results if r['status'] == 'error')
    
    report.append(f"Total files processed: {len(results)}")
    report.append(f"Successfully migrated: {success_count}")
    report.append(f"No changes needed: {no_change_count}")
    report.append(f"Errors encountered: {error_count}")
    report.append("")
    
    # æˆåŠŸã—ãŸç§»è¡Œã®è©³ç´°
    if success_count > 0:
        report.append("=== Successfully Migrated Files ===")
        for result in results:
            if result['status'] == 'success':
                report.append(f"\nğŸ“„ {result['file']}")
                report.append(f"   Backup: {result['backup_created']}")
                report.append(f"   Imports added: {result['imports_added']}")
                for change in result['changes']:
                    report.append(f"   âœ… {change}")
    
    # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°
    if error_count > 0:
        report.append("\n=== Errors ===")
        for result in results:
            if result['status'] == 'error':
                report.append(f"\nâŒ {result['file']}: {result['error']}")
    
    report.append("\n=== Next Steps ===")
    report.append("1. Test the migrated files to ensure functionality")
    report.append("2. Run the test suite to verify compatibility")
    report.append("3. Remove backup files after verification")
    report.append("4. Update any remaining hardcoded constants manually")
    
    return "\n".join(report)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ” Searching for files with duplicate constants...")
    
    # é‡è¤‡ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    files_to_migrate = find_files_with_duplicates()
    
    if not files_to_migrate:
        print("âœ… No duplicate constants found!")
        return
    
    print(f"\nğŸ“ Found {len(files_to_migrate)} files with duplicates:")
    for file_path in files_to_migrate:
        print(f"   - {file_path.name}")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèª
    response = input(f"\nğŸ¤” Proceed with migration? (y/N): ").strip().lower()
    if response != 'y':
        print("Migration cancelled.")
        return
    
    print("\nğŸš€ Starting migration...")
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»è¡Œ
    results = []
    for file_path in files_to_migrate:
        print(f"Processing {file_path.name}...", end=" ")
        result = migrate_file(file_path)
        results.append(result)
        
        if result['status'] == 'success':
            print("âœ…")
        elif result['status'] == 'no_changes':
            print("â–")
        else:
            print("âŒ")
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = generate_migration_report(results)
    print(f"\n{report}")
    
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    report_path = PROJECT_ROOT / "migration_report.txt"
    report_path.write_text(report, encoding='utf-8')
    print(f"\nğŸ“„ Detailed report saved to: {report_path}")


if __name__ == "__main__":
    main()


# æ‰‹å‹•å®Ÿè¡Œã®å ´åˆã®ä½¿ç”¨ä¾‹
"""
# å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ã‚’è‡ªå‹•ä¿®æ­£
python scripts/deduplicate_constants.py

# ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ä¿®æ­£ï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆä¿®æ­£ç‰ˆï¼‰
from deduplicate_constants import migrate_file
from pathlib import Path

result = migrate_file(Path("src/earnings_swing.py"))
print(result)
"""