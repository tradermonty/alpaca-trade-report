"""
æ®‹å­˜ToDoãƒã‚§ãƒƒã‚«ãƒ¼
ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹å†…ã®æœªå®Œäº†ã‚¿ã‚¹ã‚¯ã¨æ”¹å–„ç‚¹ã‚’ç‰¹å®š
"""

import ast
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple
from dataclasses import dataclass

PROJECT_ROOT = Path(__file__).parent.parent
SRC_DIR = PROJECT_ROOT / "src"

@dataclass
class RemainingIssue:
    """æ®‹å­˜å•é¡Œ"""
    file_path: str
    issue_type: str
    description: str
    line_number: int
    severity: str  # 'high', 'medium', 'low'
    code_snippet: str

class RemainingTodoChecker:
    def __init__(self):
        self.issues: List[RemainingIssue] = []
    
    def check_global_variables(self):
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®æ®‹å­˜ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ” Checking for remaining global variables...")
        
        global_patterns = [
            r'global\s+.*order_status',
            r'global\s+.*test_mode', 
            r'global\s+.*test_datetime',
            r'global\s+.*POSITION_SIZE',
            r'order_status\s*=\s*\{',
            r'test_mode\s*=\s*(True|False)',
            r'POSITION_SIZE\s*=\s*\d+'
        ]
        
        for py_file in SRC_DIR.glob("*.py"):
            if py_file.name.startswith('test_') or py_file.name.startswith('__'):
                continue
                
            try:
                content = py_file.read_text(encoding='utf-8')
                lines = content.split('\n')
                
                for i, line in enumerate(lines, 1):
                    for pattern in global_patterns:
                        if re.search(pattern, line):
                            self.issues.append(RemainingIssue(
                                file_path=str(py_file),
                                issue_type='global_variable',
                                description=f'Global variable usage detected: {line.strip()}',
                                line_number=i,
                                severity='high',
                                code_snippet=line.strip()
                            ))
                            
            except Exception as e:
                print(f"Error checking {py_file}: {e}")
    
    def check_circular_dependencies(self):
        """å¾ªç’°ä¾å­˜ã®æ®‹å­˜ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ”— Checking for remaining circular dependencies...")
        
        risky_imports = [
            r'from\s+orb\s+import',
            r'import\s+orb\s*$',
        ]
        
        for py_file in SRC_DIR.glob("*.py"):
            if py_file.name == 'orb.py':
                continue
                
            try:
                content = py_file.read_text(encoding='utf-8')
                lines = content.split('\n')
                
                for i, line in enumerate(lines, 1):
                    for pattern in risky_imports:
                        if re.search(pattern, line):
                            self.issues.append(RemainingIssue(
                                file_path=str(py_file),
                                issue_type='circular_dependency',
                                description=f'Direct orb.py import detected: {line.strip()}',
                                line_number=i,
                                severity='high',
                                code_snippet=line.strip()
                            ))
                            
            except Exception as e:
                print(f"Error checking {py_file}: {e}")
    
    def check_code_duplication(self):
        """ã‚³ãƒ¼ãƒ‰é‡è¤‡ã®æ®‹å­˜ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ“‹ Checking for remaining code duplication...")
        
        duplication_patterns = [
            r'TZ_NY\s*=\s*ZoneInfo\(',
            r'TZ_UTC\s*=\s*ZoneInfo\(',
            r'ALPACA_ACCOUNT\s*=\s*[\'\"](live|paper)[\'\"]\s*$',
        ]
        
        for py_file in SRC_DIR.glob("*.py"):
            if py_file.name == 'common_constants.py':
                continue
                
            try:
                content = py_file.read_text(encoding='utf-8')
                lines = content.split('\n')
                
                for i, line in enumerate(lines, 1):
                    for pattern in duplication_patterns:
                        if re.search(pattern, line):
                            self.issues.append(RemainingIssue(
                                file_path=str(py_file),
                                issue_type='code_duplication',
                                description=f'Potential code duplication: {line.strip()}',
                                line_number=i,
                                severity='medium',
                                code_snippet=line.strip()
                            ))
                            
            except Exception as e:
                print(f"Error checking {py_file}: {e}")
    
    def check_naming_inconsistencies(self):
        """å‘½åè¦å‰‡ã®ä¸çµ±ä¸€ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ“ Checking for naming inconsistencies...")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®ç•¥èªä½¿ç”¨
        abbreviation_files = [
            'orb.py', 'orb_short.py', 'orb_refactored.py'
        ]
        
        for filename in abbreviation_files:
            file_path = SRC_DIR / filename
            if file_path.exists():
                self.issues.append(RemainingIssue(
                    file_path=str(file_path),
                    issue_type='naming_inconsistency',
                    description=f'File uses abbreviation "orb" instead of descriptive name',
                    line_number=1,
                    severity='low',
                    code_snippet=f'Filename: {filename}'
                ))
    
    def check_documentation_quality(self):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå“è³ªã®å•é¡Œãƒã‚§ãƒƒã‚¯"""
        print("ğŸ“š Checking documentation quality issues...")
        
        for py_file in SRC_DIR.glob("*.py"):
            try:
                content = py_file.read_text(encoding='utf-8')
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        if not node.name.startswith('_'):  # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆé–¢æ•°ä»¥å¤–
                            docstring = ast.get_docstring(node)
                            if not docstring:
                                self.issues.append(RemainingIssue(
                                    file_path=str(py_file),
                                    issue_type='missing_documentation',
                                    description=f'Function {node.name} lacks documentation',
                                    line_number=node.lineno,
                                    severity='medium',
                                    code_snippet=f'def {node.name}(...)'
                                ))
                            elif len(docstring.strip()) < 20:
                                self.issues.append(RemainingIssue(
                                    file_path=str(py_file),
                                    issue_type='poor_documentation',
                                    description=f'Function {node.name} has insufficient documentation',
                                    line_number=node.lineno,
                                    severity='low',
                                    code_snippet=f'"""_{docstring[:30]}..."""'
                                ))
                            
            except Exception as e:
                print(f"Error checking documentation in {py_file}: {e}")
    
    def check_test_coverage(self):
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã®å•é¡Œãƒã‚§ãƒƒã‚¯"""
        print("ğŸ§ª Checking test coverage...")
        
        src_files = set(f.stem for f in SRC_DIR.glob("*.py") 
                       if not f.name.startswith('__') and not f.name.startswith('test_'))
        
        test_dir = PROJECT_ROOT / "tests"
        if test_dir.exists():
            test_files = set()
            for test_file in test_dir.rglob("test_*.py"):
                # test_xxx.py ã‹ã‚‰ xxx ã‚’æŠ½å‡º
                base_name = test_file.stem.replace('test_', '')
                test_files.add(base_name)
            
            missing_tests = src_files - test_files
            
            for missing in missing_tests:
                if missing not in ['__init__', 'main']:
                    self.issues.append(RemainingIssue(
                        file_path=f"src/{missing}.py",
                        issue_type='missing_test',
                        description=f'Module {missing} lacks corresponding test file',
                        line_number=1,
                        severity='medium',
                        code_snippet=f'Missing: tests/test_{missing}.py'
                    ))
    
    def check_deprecated_patterns(self):
        """éæ¨å¥¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒã‚§ãƒƒã‚¯"""
        print("âš ï¸ Checking for deprecated patterns...")
        
        deprecated_patterns = [
            (r'import\s+alpaca_trade_api', 'Direct alpaca_trade_api import (use api_clients instead)'),
            (r'\.get_calendar\(', 'Direct calendar access (consider using centralized method)'),
            (r'print\s*\(', 'Print statement (should use logger)'),
            (r'time\.sleep\((?!.*test)', 'Direct time.sleep (consider using config values)'),
        ]
        
        for py_file in SRC_DIR.glob("*.py"):
            try:
                content = py_file.read_text(encoding='utf-8')
                lines = content.split('\n')
                
                for i, line in enumerate(lines, 1):
                    for pattern, description in deprecated_patterns:
                        if re.search(pattern, line) and not line.strip().startswith('#'):
                            self.issues.append(RemainingIssue(
                                file_path=str(py_file),
                                issue_type='deprecated_pattern',
                                description=description,
                                line_number=i,
                                severity='low',
                                code_snippet=line.strip()
                            ))
                            
            except Exception as e:
                print(f"Error checking deprecated patterns in {py_file}: {e}")
    
    def generate_summary_report(self) -> str:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        # å•é¡Œã‚¿ã‚¤ãƒ—åˆ¥ã®é›†è¨ˆ
        issue_counts = {}
        severity_counts = {'high': 0, 'medium': 0, 'low': 0}
        
        for issue in self.issues:
            issue_counts[issue.issue_type] = issue_counts.get(issue.issue_type, 0) + 1
            severity_counts[issue.severity] += 1
        
        report = ["=== æ®‹å­˜ToDoãƒ»æ”¹å–„ç‚¹ã‚µãƒãƒªãƒ¼ ===\n"]
        
        # ç·åˆçµ±è¨ˆ
        report.append("== ğŸ“Š ç·åˆçµ±è¨ˆ ==")
        report.append(f"ç·å•é¡Œæ•°: {len(self.issues)}")
        report.append(f"é«˜å„ªå…ˆåº¦: {severity_counts['high']}ä»¶")
        report.append(f"ä¸­å„ªå…ˆåº¦: {severity_counts['medium']}ä»¶") 
        report.append(f"ä½å„ªå…ˆåº¦: {severity_counts['low']}ä»¶")
        report.append("")
        
        # å•é¡Œã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
        report.append("== ğŸ“‹ å•é¡Œã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ ==")
        for issue_type, count in sorted(issue_counts.items(), key=lambda x: x[1], reverse=True):
            report.append(f"{issue_type}: {count}ä»¶")
        report.append("")
        
        # é«˜å„ªå…ˆåº¦å•é¡Œã®è©³ç´°
        high_priority = [issue for issue in self.issues if issue.severity == 'high']
        if high_priority:
            report.append("== ğŸš¨ é«˜å„ªå…ˆåº¦å•é¡Œ (è¦å¯¾å¿œ) ==")
            for issue in high_priority[:10]:  # ä¸Šä½10ä»¶
                file_name = Path(issue.file_path).name
                report.append(f"ğŸ“„ {file_name}:{issue.line_number}")
                report.append(f"   {issue.description}")
                report.append(f"   ã‚³ãƒ¼ãƒ‰: {issue.code_snippet}")
                report.append("")
        
        # ä¸­å„ªå…ˆåº¦å•é¡Œã®ã‚µãƒãƒªãƒ¼
        medium_priority = [issue for issue in self.issues if issue.severity == 'medium']
        if medium_priority:
            report.append("== âš ï¸ ä¸­å„ªå…ˆåº¦å•é¡Œ (æ”¹å–„æ¨å¥¨) ==")
            medium_by_type = {}
            for issue in medium_priority:
                if issue.issue_type not in medium_by_type:
                    medium_by_type[issue.issue_type] = []
                medium_by_type[issue.issue_type].append(issue)
            
            for issue_type, issues in medium_by_type.items():
                report.append(f"{issue_type}: {len(issues)}ä»¶")
                for issue in issues[:3]:  # å„ã‚¿ã‚¤ãƒ—3ä»¶ã¾ã§
                    file_name = Path(issue.file_path).name
                    report.append(f"  - {file_name}:{issue.line_number} {issue.description}")
            report.append("")
        
        # å®Œäº†æ¸ˆã¿ã‚¿ã‚¹ã‚¯ã®ç¢ºèª
        report.append("== âœ… å®Œäº†æ¸ˆã¿ä¸»è¦ã‚¿ã‚¹ã‚¯ ==")
        report.append("1. âœ… å¾ªç’°ä¾å­˜ã®è§£æ±º (ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åˆ†é›¢ãƒ‘ã‚¿ãƒ¼ãƒ³)")
        report.append("2. âœ… ã‚³ãƒ¼ãƒ‰é‡è¤‡ã®å‰Šé™¤ (å…±é€šå®šæ•°ã®çµ±ä¸€)")
        report.append("3. âœ… å‘½åè¦å‰‡ã®çµ±ä¸€ (å®šæ•°ã®UPPER_CASEåŒ–)")
        report.append("4. âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå“è³ªæ¨™æº–ã®ç­–å®š")
        report.append("5. âœ… ä¾å­˜é–¢ä¿‚åˆ†æã¨ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°è¨ˆç”»")
        report.append("")
        
        # æ¨å¥¨æ¬¡ã‚¹ãƒ†ãƒƒãƒ—
        report.append("== ğŸš€ æ¨å¥¨æ¬¡ã‚¹ãƒ†ãƒƒãƒ— ==")
        if severity_counts['high'] > 0:
            report.append("1. ğŸš¨ é«˜å„ªå…ˆåº¦å•é¡Œã®è§£æ±º")
        if severity_counts['medium'] > 10:
            report.append("2. âš ï¸ ä¸­å„ªå…ˆåº¦å•é¡Œã®æ®µéšçš„æ”¹å–„")
        if issue_counts.get('missing_test', 0) > 0:
            report.append("3. ğŸ§ª ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã®å‘ä¸Š")
        if issue_counts.get('missing_documentation', 0) > 0:
            report.append("4. ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå“è³ªã®ç¶™ç¶šæ”¹å–„")
        
        report.append("")
        report.append("== ğŸ“ˆ å“è³ªæ”¹å–„ã®æˆæœ ==")
        report.append("- ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: å¾ªç’°ä¾å­˜ã‚’è§£æ¶ˆã€ä¿å®ˆæ€§å‘ä¸Š")
        report.append("- ğŸ”„ ã‚³ãƒ¼ãƒ‰å“è³ª: é‡è¤‡å‰Šé™¤ã€çµ±ä¸€ã•ã‚ŒãŸå‘½åè¦å‰‡")  
        report.append("- ğŸ“– ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: çµ±ä¸€æ¨™æº–ã€APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ä½œæˆ")
        report.append("- ğŸ›¡ï¸ å®‰å®šæ€§: ä¾å­˜æ€§æ³¨å…¥ã€çŠ¶æ…‹ç®¡ç†ã®æ”¹å–„")
        
        return "\n".join(report)
    
    def run_all_checks(self):
        """å…¨ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
        print("ğŸ” Starting comprehensive remaining todo check...\n")
        
        self.check_global_variables()
        self.check_circular_dependencies()
        self.check_code_duplication()
        self.check_naming_inconsistencies()
        self.check_documentation_quality()
        self.check_test_coverage()
        self.check_deprecated_patterns()
        
        return self.generate_summary_report()

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    checker = RemainingTodoChecker()
    report = checker.run_all_checks()
    
    print(f"\n{report}")
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    report_path = PROJECT_ROOT / "remaining_todo_report.txt"
    report_path.write_text(report, encoding='utf-8')
    print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_path}")
    
    # å•é¡Œæ•°ã®ã‚µãƒãƒªãƒ¼
    high_count = sum(1 for issue in checker.issues if issue.severity == 'high')
    medium_count = sum(1 for issue in checker.issues if issue.severity == 'medium') 
    low_count = sum(1 for issue in checker.issues if issue.severity == 'low')
    
    print(f"\nğŸ“Š æœ€çµ‚çµæœ: {len(checker.issues)}ä»¶ã®æ”¹å–„ç‚¹ã‚’æ¤œå‡º")
    print(f"   ğŸš¨ é«˜å„ªå…ˆåº¦: {high_count}ä»¶")
    print(f"   âš ï¸ ä¸­å„ªå…ˆåº¦: {medium_count}ä»¶")
    print(f"   ğŸ’¡ ä½å„ªå…ˆåº¦: {low_count}ä»¶")
    
    if high_count == 0:
        print("\nğŸ‰ é«˜å„ªå…ˆåº¦ã®å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼")
    else:
        print(f"\nâš ï¸ {high_count}ä»¶ã®é«˜å„ªå…ˆåº¦å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚å¯¾å¿œã‚’æ¨å¥¨ã—ã¾ã™ã€‚")

if __name__ == "__main__":
    main()